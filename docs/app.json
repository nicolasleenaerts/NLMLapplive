[{"name":"app.R","content":"#### Load libraries ####\nlibrary(shiny)\nlibrary(ggplot2)\n\ndownloadButton <- function(...) {\n  tag <- shiny::downloadButton(...)\n  tag$attribs$download <- NULL\n  tag\n}\n\nelastic_net_wrapper_pooled <- function(data, outcome=NULL, by=NULL,predictors_con=NULL,predictors_cat=NULL,\n                                       between_predictors_con=NULL,between_predictors_cat=NULL,\n                                       split=80, outer_cv=NULL,stratified=T,scaling=T,repeated_cv=1,ensr_cv=10,\n                                       ensr_alphas=seq(0, 1, length = 10),ensr_lambdas=100,seed=404,\n                                       stop_test=NULL,shuffle=F,family='binary',pred_min=NULL,pred_max=NULL,prefer_sensitivity=T){\n  # required packages\n  `%!in%` = Negate(`%in%`)\n  \n  # combine predictors\n  predictors = c(predictors_con,predictors_cat,between_predictors_con,between_predictors_cat)\n  \n  # create list of x and y datasets to be analyzed\n  analysis_list = list()\n  if (is.null(outer_cv)==T){\n    analysis_list[[1]] = list()\n    analysis_list[[1]][[1]] = data.frame()\n    analysis_list[[1]][[2]] = data.frame()\n    analysis_list[[1]][[3]] = list()\n    analysis_list[[1]][[4]] = list()\n  }\n  else{\n    for(nfold in 1:outer_cv){\n      analysis_list[[nfold]] = list()\n      analysis_list[[nfold]][[1]] = data.frame()\n      analysis_list[[nfold]][[2]] = data.frame()\n      analysis_list[[nfold]][[3]] = list()\n      analysis_list[[nfold]][[4]] = list()\n    }\n  }\n  \n  # Loop over by\n  for (by_index in 1:length(unique(unlist(data[by])))){\n    by_entry = unique(unlist(data[by]))[by_index]\n    data_by = subset(data,unlist(data[by])==by_entry)\n    \n    # shuffle dataset to lose time contingency for CV\n    if (shuffle==T){\n      set.seed(seed)\n      data_by = data_by[sample(nrow(data_by)),]\n    }\n    \n    # split data into y and x\n    y_by = data_by[outcome]\n    x_by = data_by[predictors]\n    \n    # split x and y into training and testing data\n    if (is.null(outer_cv)==T){\n      # performing stratified split\n      if(stratified==T){\n        if (family=='binary'){\n          # get indices\n          set.seed(seed)\n          my_train_ind_no_y =  sample(which(y_by==0), size = split/100*length(which(y_by==0)))\n          set.seed(seed)\n          my_train_ind_y =  sample(which(y_by==1), size = split/100*length(which(y_by==1)))\n          # split data\n          y_train_by = y_by[c(my_train_ind_no_y,my_train_ind_y),]\n          y_test_by =y_by[-c(my_train_ind_no_y,my_train_ind_y),]\n          x_train_by = x_by[c(my_train_ind_no_y,my_train_ind_y),]\n          x_test_by = x_by[-c(my_train_ind_no_y,my_train_ind_y),]\n        }\n        else if (family=='continuous'){\n          # get indices\n          set.seed(seed)\n          my_train_ind =  caret::createDataPartition(as.matrix(y_by), p = split/100, list = T,groups=min(3,nrow(y_by)))\n          # split data\n          y_train_by = y_by[c(unlist(my_train_ind)),]\n          y_test_by =y_by[-c(unlist(my_train_ind)),]\n          x_train_by = x_by[c(unlist(my_train_ind)),]\n          x_test_by = x_by[-c(unlist(my_train_ind)),]\n        }\n        #scaling numeric data on the within level\n        if (scaling==T){\n          for(variable in predictors_con){\n            mean_variable = mean(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n            sd_variable = sd(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n            if(sd_variable==0){\n              x_train_by[,variable] = as.numeric(unlist(x_train_by[,variable]))-mean_variable\n              x_test_by[,variable] = as.numeric(unlist(x_test_by[,variable]))-mean_variable\n              next}\n            x_train_by[,variable] = (as.numeric(unlist(x_train_by[,variable]))-mean_variable)/sd_variable\n            x_test_by[,variable] = (as.numeric(unlist(x_test_by[,variable]))-mean_variable)/sd_variable\n          }\n        }\n        # add to analysis list\n        analysis_list[[1]][[1]][(nrow(analysis_list[[1]][[1]])+1):(nrow(analysis_list[[1]][[1]])+length(y_train_by)),1] = y_train_by\n        analysis_list[[1]][[2]][(nrow(analysis_list[[1]][[2]])+1):(nrow(analysis_list[[1]][[2]])+nrow(x_train_by)),1:ncol(x_train_by)] = x_train_by\n        analysis_list[[1]][[3]][[by_index]] = y_test_by\n        analysis_list[[1]][[4]][[by_index]] = x_test_by\n      }\n      # performing non-stratified split\n      else if(stratified==F){\n        set.seed(seed)\n        my_train_ind =  sample(c(1:nrow(y_by)), size = split/100*nrow(y_by))\n        y_train_by = y_by[c(my_train_ind),]\n        y_test_by =y_by[-c(my_train_ind),]\n        x_train_by = x_by[c(my_train_ind),]\n        x_test_by = x_by[-c(my_train_ind),]\n        \n        #scaling numeric data on the within level\n        if (scaling==T){\n          for(variable in predictors_con){\n            mean_variable = mean(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n            sd_variable = sd(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n            if(sd_variable==0){\n              x_train_by[,variable] = as.numeric(unlist(x_train_by[,variable]))-mean_variable\n              x_test_by[,variable] = as.numeric(unlist(x_test_by[,variable]))-mean_variable\n              next}\n            x_train_by[,variable] = (as.numeric(unlist(x_train_by[,variable]))-mean_variable)/sd_variable\n            x_test_by[,variable] = (as.numeric(unlist(x_test_by[,variable]))-mean_variable)/sd_variable\n          }\n        }\n        # add to analysis list\n        analysis_list[[1]][[1]][(nrow(analysis_list[[1]][[1]])+1):(nrow(analysis_list[[1]][[1]])+length(y_train_by)),1] = y_train_by\n        analysis_list[[1]][[2]][(nrow(analysis_list[[1]][[2]])+1):(nrow(analysis_list[[1]][[2]])+nrow(x_train_by)),1:ncol(x_train_by)] = x_train_by\n        analysis_list[[1]][[3]][[by_index]] = y_test_by\n        analysis_list[[1]][[4]][[by_index]] = x_test_by\n      }\n    }\n    # creating datasets for cross-validation\n    else {\n      if(stratified==T){\n        # creating folds\n        set.seed(seed)\n        folds <- splitTools::create_folds(as.numeric(unlist(y_by)),k = outer_cv,type='stratified')\n        # creating datasets\n        for(nfold in 1:length(folds)){\n          y_train_by <- y_by[c(folds[[nfold]]), ]\n          y_test_by <- y_by[-c(folds[[nfold]]), ]\n          x_train_by <- x_by[c(folds[[nfold]]), ]\n          x_test_by <- x_by[-c(folds[[nfold]]), ]\n          \n          #scaling numeric data on the within level\n          if (scaling==T){\n            for(variable in predictors_con){\n              mean_variable = mean(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n              sd_variable = sd(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n              if(sd_variable==0){\n                x_train_by[,variable] = as.numeric(unlist(x_train_by[,variable]))-mean_variable\n                x_test_by[,variable] = as.numeric(unlist(x_test_by[,variable]))-mean_variable\n                next}\n              x_train_by[,variable] = (as.numeric(unlist(x_train_by[,variable]))-mean_variable)/sd_variable\n              x_test_by[,variable] = (as.numeric(unlist(x_test_by[,variable]))-mean_variable)/sd_variable\n            }\n          }\n          # add to analysis list\n          analysis_list[[nfold]][[1]][(nrow(analysis_list[[nfold]][[1]])+1):(nrow(analysis_list[[nfold]][[1]])+length(y_train_by)),1] = y_train_by\n          analysis_list[[nfold]][[2]][(nrow(analysis_list[[nfold]][[2]])+1):(nrow(analysis_list[[nfold]][[2]])+nrow(x_train_by)),1:ncol(x_train_by)] = x_train_by\n          analysis_list[[nfold]][[3]][[by_index]] = y_test_by\n          analysis_list[[nfold]][[4]][[by_index]] = x_test_by\n        }\n      }\n      else if(stratified==F){\n        set.seed(seed)\n        folds <- splitTools::create_folds(as.numeric(unlist(y_by)),k = outer_cv,type='basic')\n        for(nfold in 1:length(folds)){\n          y_train_by <- y_by[c(folds[[nfold]]), ]\n          y_test_by <- y_by[-c(folds[[nfold]]), ]\n          x_train_by <- x_by[c(folds[[nfold]]), ]\n          x_test_by <- x_by[-c(folds[[nfold]]), ]\n          \n          #scaling numeric data on the within level\n          if (scaling==T){\n            for(variable in predictors_con){\n              mean_variable = mean(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n              sd_variable = sd(as.numeric(unlist(x_train_by[,variable])),na.rm=T)\n              if(sd_variable==0){\n                x_train_by[,variable] = as.numeric(unlist(x_train_by[,variable]))-mean_variable\n                x_test_by[,variable] = as.numeric(unlist(x_test_by[,variable]))-mean_variable\n                next}\n              x_train_by[,variable] = (as.numeric(unlist(x_train_by[,variable]))-mean_variable)/sd_variable\n              x_test_by[,variable] = (as.numeric(unlist(x_test_by[,variable]))-mean_variable)/sd_variable\n            }\n          }\n          # add to analysis list\n          analysis_list[[nfold]][[1]][(nrow(analysis_list[[nfold]][[1]])+1):(nrow(analysis_list[[nfold]][[1]])+length(y_train_by)),1] = y_train_by\n          analysis_list[[nfold]][[2]][(nrow(analysis_list[[nfold]][[2]])+1):(nrow(analysis_list[[nfold]][[2]])+nrow(x_train_by)),1:ncol(x_train_by)] = x_train_by\n          analysis_list[[nfold]][[3]][[by_index]] = y_test_by\n          analysis_list[[nfold]][[4]][[by_index]] = x_test_by\n        }\n      }\n    }\n  }\n  \n  # Scaling numeric data on the between level\n  if (scaling==T){\n    for (entry in 1:length(analysis_list)){\n      for(variable in between_predictors_con){\n        mean_variable = mean(as.numeric(unlist(analysis_list[[entry]][[2]][,variable])),na.rm=T)\n        sd_variable = sd(as.numeric(unlist(analysis_list[[entry]][[2]][,variable])),na.rm=T)\n        if(sd_variable==0){\n          analysis_list[[entry]][[2]][,variable] = as.numeric(unlist(analysis_list[[entry]][[2]][,variable]))-mean_variable\n          analysis_list[[entry]][[4]] = lapply(analysis_list[[entry]][[4]], function (x){x[,variable]=(x[,variable]-mean_variable)/sd_variable\n          return(x)})\n          next}\n        analysis_list[[entry]][[2]][,variable] = (as.numeric(unlist(analysis_list[[entry]][[2]][,variable]))-mean_variable)/sd_variable\n        analysis_list[[entry]][[4]] = lapply(analysis_list[[entry]][[4]], function (x){x[,variable]=(x[,variable]-mean_variable)/sd_variable\n        return(x)})\n      }\n    }\n  }\n  \n  # creating the results dataframe\n  results_list = list()\n  \n  if (family==('binary')){\n    results_df_model = data.frame(matrix(ncol = (3+length(predictors))))\n    colnames(results_df_model) = c('fold','nrow_train','ny_train',predictors)\n    results_df_pooled = data.frame(matrix(ncol = (10)))\n    colnames(results_df_pooled) = c('by','fold','nrow_test','ny_test','AUC','sensitivity','specificity',\n                                    'accuracy','PPV','NPV')\n  }\n  else if (family==('continuous')){\n    results_df_model = data.frame(matrix(ncol = (3+length(predictors))))\n    colnames(results_df_model) = c('fold','nrow_train','mean_y_train',predictors)\n    results_df_pooled = data.frame(matrix(ncol = (9)))\n    colnames(results_df_pooled) = c('by','fold','nrow_test','mean_y_test','R2','R2_adjusted','RMSE','MSE',\n                                    'MAE')\n  }\n  \n  # Training and testing the elastic net\n  for (entry in 1:length(analysis_list)){\n    \n    # getting the training and testing data\n    y_train_entry = analysis_list[[entry]][[1]]\n    x_train_entry= analysis_list[[entry]][[2]]\n    \n    # identify binary data\n    binary_predictors = colnames(x_train_entry)[which(apply(x_train_entry,2,function(x) { all(x %in% 0:1) })==T)]\n    binary_predictors = subset(binary_predictors,binary_predictors%!in%colnames(x_train_entry)[grepl('numeric',sapply(x_train_entry,class))])\n    \n    # transforming to a data matrix\n    x_train_entry = data.matrix(x_train_entry)\n    \n    # correcting dummy coded variables\n    x_train_entry[,c(binary_predictors)]<- x_train_entry[,c(binary_predictors)]-1\n    \n    # removing variables with no variance from the training data\n    removed_names = c()\n    for (name in colnames(x_train_entry)){\n      if (length(unique(x_train_entry[,name]))<2){\n        x_train_entry = x_train_entry[, !colnames(x_train_entry) %in% c(name)]\n        removed_names[(length(removed_names)+1)]=name\n      }\n    }\n    \n    # finding best lambda and alpha\n    \n    # creating a variable for storing the crossvalidation results for the alphas and the lambdas\n    MSEs <- NULL\n    \n    # store variables for  ensr\n    x_train_entry <<- x_train_entry\n    y_train_entry <<- y_train_entry\n    ensr_lambdas <<- ensr_lambdas\n    ensr_cv <<- ensr_cv\n    ensr_alphas <<- ensr_alphas\n    \n    # get ensr family\n    ensr_family <<- ifelse(family=='binary','binomial','gaussian')\n    \n    for (repeated_cv_number in 1:repeated_cv){\n      \n      # setting the seed\n      set.seed(repeated_cv_number)\n      # selecting the best alpha and lambda for this seed\n      ensr_obj <- ensr::ensr(y =data.matrix(y_train_entry), x = x_train_entry,nlambda=ensr_lambdas,nfolds = ensr_cv,\n                       alphas = ensr_alphas,family=ensr_family,standardize = F)\n      ensr_obj_summary <- summary(object = ensr_obj)\n      \n      # storing the results\n      MSEs <- cbind(MSEs,ensr_obj_summary$cvm)\n    }\n    \n    # converting the cross validation results to a dataframe\n    MSEs <- as.data.frame(MSEs)\n    MSEs$rowMeans <- rowMeans(MSEs)\n    \n    # adding the alphas and lambdas that we used\n    # these are the same for every seed!\n    MSEs$lambdas <- ensr_obj_summary$lambda\n    MSEs$alphas<- ensr_obj_summary$alpha\n    MSEs <- MSEs[order(MSEs$rowMeans,decreasing = F), ]\n    \n    # Selecting the  alpha and the lambda of the best model\n    alpha.min <- MSEs$alphas[1]\n    lambda.min <- MSEs$lambdas[1]\n    \n    # fitting the elastic net model and getting the estimates for the variables\n    elastic_model <- glmnet::glmnet(y =data.matrix(y_train_entry), x = x_train_entry, family = ensr_family, alpha = alpha.min,\n                            lambda=lambda.min,standardize = F)\n    estimates <- elastic_model$beta\n    \n    # having at least one parameter\n    while (length(which(estimates[,1]!=0))<1){\n      MSEs <- MSEs[-1,]\n      lambda.min <- MSEs$lambdas[1]\n      alpha.min <- MSEs$alphas[1]\n      elastic_model <- glmnet::glmnet(y =data.matrix(y_train_entry), x = x_train_entry, family = ensr_family,\n                              alpha = alpha.min,lambda=lambda.min,standardize = F)\n      estimates <- elastic_model$beta\n    }\n    \n    # Store predictors model\n    if (family==('binary')){\n      results_df_model[entry,'fold'] = entry\n      results_df_model[entry,'nrow_train']=nrow(x_train_entry)\n      results_df_model[entry,'ny_train']=sum(as.numeric(as.character(unlist(y_train_entry))))\n    }\n    else if (family==('continuous')){\n      results_df_model[entry,'fold'] = entry\n      results_df_model[entry,'nrow_train']=nrow(x_train_entry)\n      results_df_model[entry,'mean_y_train']=mean(as.numeric(as.character(unlist(y_train_entry))))\n    }\n    \n    # storing estimates\n    for (predictor in predictors){\n      index = which(rownames(estimates)==predictor)\n      if (length(index)==0){\n        results_df_model[entry,predictor]<- NA\n      }\n      else{\n        results_df_model[entry,predictor]<- estimates[index]\n      }\n    }\n    \n    # calculate metrics model\n    for (by_index in 1:length(unique(unlist(data[by])))){\n      by_entry = unique(unlist(data[by]))[by_index]\n      # getting test data\n      y_test_by = analysis_list[[entry]][[3]][[by_index]]\n      x_test_by = analysis_list[[entry]][[4]][[by_index]]\n      \n      # Stopping if there aren't enough observations in the training data\n      if (is.null(stop_test)==F){\n        if (family == 'binary'){if (sum(as.numeric(as.character(unlist(y_test_by))))<stop_test){next}}\n        else if (family=='continuous'){if (length(unlist(y_test_by))<stop_test){next}}\n      }\n      \n      # having at least two levels\n      if(length(unique(unlist(y_test_by)))<2){next}\n      \n      # transforming to a data matrix\n      x_test_by = data.matrix(x_test_by)\n      \n      # correcting dummy coded variables\n      x_test_by[,c(binary_predictors)]<- x_test_by[,c(binary_predictors)]-1\n      \n      # remove variables which were removed before\n      for (name in removed_names){\n        x_test_by = x_test_by[, !colnames(x_test_by) %in% c(name)]\n      }\n      \n      if (family=='binary'){\n        # AUC\n        predictions = predict(elastic_model, newx=x_test_by,type = \"response\")\n        model_roc =  pROC::roc(unlist(y_test_by),as.numeric(predictions),direction=\"<\",quiet=T)\n        model_coords = pROC::coords(model_roc,\"best\", ret=c(\"threshold\", \"specificity\", \"sensitivity\"), transpose=FALSE)\n        model_auc = pROC::auc(model_roc)\n        \n        # Sensitivity and specificity\n        if (prefer_sensitivity==T){\n          coords_to_pick = which(model_coords$sensitivity==max(model_coords$sensitivity))\n        }\n        else {\n          coords_to_pick = which(model_coords$specificity==max(model_coords$specificity))\n        }\n        model_spec <- model_coords[coords_to_pick,2]\n        model_sens <- model_coords[coords_to_pick,3]\n        \n        # store predictions\n        predictions_all[test_indices[[entry]]] = predictions\n        \n        # accuracy, PPV, NPV\n        predictions_bin = ifelse(predictions>model_coords$threshold[coords_to_pick],1,0)\n        confmatrix <- caret::confusionMatrix(as.factor(predictions_bin),as.factor(unlist(y_test_by)),positive='1')\n        \n        # storing metrics\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'by']=by_entry\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'fold']=entry\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'nrow_test']=nrow(x_test_by)\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'ny_test']=sum(as.numeric(as.character(unlist(y_test_by))))\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'AUC']=model_auc\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'sensitivity']=model_sens\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'specificity']=model_spec\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'accuracy']=confmatrix$overall[1]\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'PPV']=confmatrix$byClass[3]\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'NPV']=confmatrix$byClass[4]\n      }\n      else if (family=='continuous'){\n        \n        # Making predictions\n        predictions = predict(elastic_model, newx=x_test_by,type = \"response\")\n        \n        if (is.null(pred_min)==F){predictions[predictions<pred_min]=pred_min}\n        if (is.null(pred_max)==F){predictions[predictions>pred_max]=pred_max}\n        \n        # Getting R2, adjusted R2, RMSE, MSE, MAE\n        R2 = 1-(sum((y_test_by-predictions)^2)/length(y_test_by))/(sum((y_test_by-mean(unlist(y_train_entry)))^2)/length(y_test_by))\n        R2_adjusted = 1 - (1-R2)*(length(y_test_by)-1)/(length(y_test_by)-length(which(estimates!=0))-1)\n        RMSE = caret::RMSE(y_test_by,predictions)\n        MSE = RMSE^2\n        MAE = caret::MAE(y_test_by,predictions)\n        \n        # storing metrics\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'by']=by_entry\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'fold']=entry\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'nrow_test']=nrow(x_test_by)\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'mean_y_test']=mean(y_test_by)\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'R2']=R2\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'R2_adjusted']=R2_adjusted\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'RMSE']=RMSE\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'MSE']=MSE\n        results_df_pooled[((entry-1)*length(unique(unlist(data[by])))+by_index),'MAE']=MAE\n      }\n    }\n    \n    # remove stored variables\n    rm(x_train_entry,envir = .GlobalEnv)\n    rm(y_train_entry,envir = .GlobalEnv)\n    rm(ensr_lambdas,envir = .GlobalEnv)\n    rm(ensr_cv,envir = .GlobalEnv)\n    rm(ensr_alphas,envir = .GlobalEnv)\n  }\n  \n  results_list$results_pooled_model=results_df_model\n  results_list$results_by=results_df_pooled\n  \n  # return df\n  return(results_list)\n}\nelastic_net_wrapper <- function(data, outcome=NULL, predictors_con=NULL,predictors_cat=NULL, split=80, outer_cv=NULL, stratified=T,scaling=T,\n                                repeated_cv=1,ensr_cv=10,ensr_alphas=seq(0, 1, length = 10),ensr_lambdas=100,seed=404,shuffle=T,\n                                stop_train=NULL,stop_test=NULL,family='binary',pred_min=NULL,pred_max=NULL,prefer_sensitivity=T){\n  # required packages\n  `%!in%` = Negate(`%in%`)\n  \n  # combine predictors\n  predictors = c(predictors_con,predictors_cat)\n  \n  # shuffle dataset to lose time contingency for CV\n  if (shuffle==T){\n    set.seed(seed)\n    data = data[sample(nrow(data)),]\n  }\n  \n  # split data into y and x\n  y = data[outcome]\n  x = data[predictors]\n  \n  # create list to store the predictions\n  predictions_all = rep('Train',length(unlist(y)))\n  \n  # create list for test indices\n  test_indices = list()\n  \n  # create list of x and y datasets to be analyzed\n  analysis_list = list()\n  \n  # split x and y into training and testing data\n  if (is.null(outer_cv)==T){\n    # performing stratified split\n    if(stratified==T){\n      if (family=='binary'){\n        # get indices\n        set.seed(seed)\n        my_train_ind_no_y =  sample(which(y==0), size = split/100*length(which(y==0)))\n        set.seed(seed)\n        my_train_ind_y =  sample(which(y==1), size = split/100*length(which(y==1)))\n        # store test indices\n        test_indices[[1]] = c(1:length(unlist(y)))[c(1:length(unlist(y)))%!in%c(my_train_ind_no_y,my_train_ind_y)]\n        # split data\n        y_train = y[c(my_train_ind_no_y,my_train_ind_y),]\n        y_test =y[-c(my_train_ind_no_y,my_train_ind_y),]\n        x_train = x[c(my_train_ind_no_y,my_train_ind_y),]\n        x_test = x[-c(my_train_ind_no_y,my_train_ind_y),]\n        # add to analysis list\n        analysis_list[[1]] = list(y_train,y_test,x_train,x_test)\n      }\n      else if (family=='continuous'){\n        # get indices\n        set.seed(seed)\n        my_train_ind =  caret::createDataPartition(as.matrix(y), p = split/100, list = T,groups=min(3,nrow(y)))\n        # store test indices\n        test_indices[[1]] = c(1:length(unlist(y)))[c(1:length(unlist(y)))%!in%unlist(my_train_ind)]\n        # split data\n        y_train = y[c(unlist(my_train_ind)),]\n        y_test =y[-c(unlist(my_train_ind)),]\n        x_train = x[c(unlist(my_train_ind)),]\n        x_test = x[-c(unlist(my_train_ind)),]\n        # add to analysis list\n        analysis_list[[1]] = list(y_train,y_test,x_train,x_test)\n      }\n    }\n    # performing non-stratified split\n    else if(stratified==F){\n      set.seed(seed)\n      my_train_ind =  sample(c(1:nrow(y)), size = split/100*nrow(y))\n      # store test indices\n      test_indices[[1]] = c(1:length(unlist(y)))[c(1:length(unlist(y)))%!in%c(my_train_ind)]\n      # split data\n      y_train = y[c(my_train_ind),]\n      y_test =y[-c(my_train_ind),]\n      x_train = x[c(my_train_ind),]\n      x_test = x[-c(my_train_ind),]\n      # add to analysis list\n      analysis_list[[1]] = list(y_train,y_test,x_train,x_test)\n    }\n  }\n  # creating datasets for cross-validation\n  else {\n    if(stratified==T){\n      # creating folds\n      set.seed(seed)\n      folds <- splitTools::create_folds(as.numeric(unlist(y)),k = outer_cv,type='stratified')\n      # creating datasets\n      for(nfold in 1:length(folds)){\n        y_train <- y[c(folds[[nfold]]), ]\n        y_test <- y[-c(folds[[nfold]]), ]\n        x_train <- x[c(folds[[nfold]]), ]\n        x_test <- x[-c(folds[[nfold]]), ]\n        analysis_list[[nfold]] = list(y_train,y_test,x_train,x_test)\n        # store indices\n        test_indices[[nfold]] = c(1:length(unlist(y)))[c(1:length(unlist(y)))%!in%c(folds[[nfold]])]\n      }\n    }\n    else if(stratified==F){\n      set.seed(seed)\n      folds <- splitTools::create_folds(as.numeric(unlist(y)),k = outer_cv,type='basic')\n      for(nfold in 1:length(folds)){\n        y_train <- y[c(folds[[nfold]]), ]\n        y_test <- y[-c(folds[[nfold]]), ]\n        x_train <- x[c(folds[[nfold]]), ]\n        x_test <- x[-c(folds[[nfold]]), ]\n        analysis_list[[nfold]] = list(y_train,y_test,x_train,x_test)\n        # store indices\n        test_indices[[nfold]] = c(1:length(unlist(y)))[c(1:length(unlist(y)))%!in%c(folds[[nfold]])]\n      }\n    }\n  }\n  \n  # creating the results dataframe\n  if (family==('binary')){\n    results_df = data.frame(matrix(ncol = (11+length(predictors))))\n    colnames(results_df) = c('fold','nrow_train','nrow_test','ny_train','ny_test','AUC','sensitivity','specificity',\n                             'accuracy','PPV','NPV',predictors)\n  }\n  if (family==('continuous')){\n    results_df = data.frame(matrix(ncol = (10+length(predictors))))\n    colnames(results_df) = c('fold','nrow_train','nrow_test','mean_y_train','mean_y_test','R2','R2_adjusted','RMSE','MSE',\n                             'MAE',predictors)\n  }\n  \n  # Creating list for models\n  models = c()\n  \n  # Training and testing the elastic net\n  for (entry in 1:length(analysis_list)){\n    \n    # getting the training and testing data\n    y_train_entry = analysis_list[[entry]][[1]]\n    y_test_entry= analysis_list[[entry]][[2]]\n    x_train_entry= analysis_list[[entry]][[3]]\n    x_test_entry= analysis_list[[entry]][[4]]\n    \n    # Stopping if there aren't enough observations in the training data\n    if (is.null(stop_train)==F){\n      if (sum(as.numeric(as.character(unlist(y_train_entry))))<stop_train){next}\n    }\n    \n    #scaling numeric data\n    if (scaling==T){\n      for(variable in predictors_con){\n        mean_variable = mean(as.numeric(unlist(x_train_entry[,variable])),na.rm=T)\n        sd_variable = sd(as.numeric(unlist(x_train_entry[,variable])),na.rm=T)\n        x_train_entry[,variable] = (as.numeric(unlist(x_train_entry[,variable]))-mean_variable)/sd_variable\n        x_test_entry[,variable] = (as.numeric(unlist(x_test_entry[,variable]))-mean_variable)/sd_variable\n      }\n    }\n    \n    # removing variables with no variance from the training data\n    for (name in colnames(x_train_entry)){\n      if (length(unique(unlist(x_train_entry[,name])))<2){\n        x_train_entry = x_train_entry[, !colnames(x_train_entry) %in% c(name)]\n        x_test_entry = x_test_entry[, !colnames(x_test_entry) %in% c(name)]\n      }\n    }\n    \n    # identify binary data\n    binary_predictors = colnames(x_train_entry)[which(apply(x_train_entry,2,function(x) { all(x %in% 0:1) })==T)]\n    binary_predictors = subset(binary_predictors,binary_predictors%!in%colnames(x_train_entry)[grepl('numeric',sapply(x_train_entry,class))])\n    \n    # transforming to a data matrix\n    x_train_entry = data.matrix(x_train_entry)\n    x_test_entry = data.matrix(x_test_entry)\n    \n    # correcting dummy coded variables\n    x_train_entry[,c(binary_predictors)]<- x_train_entry[,c(binary_predictors)]-1\n    x_test_entry[,c(binary_predictors)]<- x_test_entry[,c(binary_predictors)]-1\n    \n    # finding best lambda and alpha\n    \n    # creating a variable for storing the crossvalidation results for the alphas and the lambdas\n    MSEs = NULL\n    \n    # store variables for  ensr\n    x_train_entry <<- x_train_entry\n    y_train_entry <<- y_train_entry\n    ensr_lambdas <<- ensr_lambdas\n    ensr_cv <<- ensr_cv\n    ensr_alphas <<- ensr_alphas\n    \n    # get ensr family\n    ensr_family <<- ifelse(family=='binary','binomial','gaussian')\n    \n    for (repeated_cv_number in 1:repeated_cv){\n      \n      # setting the seed\n      set.seed(repeated_cv_number)\n      # selecting the best alpha and lambda for this seed\n      ensr_obj = ensr::ensr(y =data.matrix(y_train_entry), x = x_train_entry,nlambda=ensr_lambdas,nfolds = ensr_cv,\n                      alphas = ensr_alphas,family=ensr_family,standardize = F)\n      ensr_obj_summary = summary(object = ensr_obj)\n      \n      # storing the results\n      MSEs = cbind(MSEs,ensr_obj_summary$cvm)\n    }\n    \n    # converting the cross validation results to a dataframe\n    MSEs = as.data.frame(MSEs)\n    MSEs$rowMeans = rowMeans(MSEs)\n    \n    # adding the alphas and lambdas that we used\n    # these are the same for every seed!\n    MSEs$lambdas = ensr_obj_summary$lambda\n    MSEs$alphas= ensr_obj_summary$alpha\n    MSEs = MSEs[order(MSEs$rowMeans,decreasing = F), ]\n    \n    # Selecting the  alpha and the lambda of the best model\n    alpha.min = MSEs$alphas[1]\n    lambda.min = MSEs$lambdas[1]\n    \n    # fitting the elastic net model and getting the estimates for the variables\n    elastic_model = glmnet::glmnet(y =data.matrix(y_train_entry), x = x_train_entry, family = ensr_family, alpha = alpha.min,\n                           lambda=lambda.min,standardize = F)\n    estimates = elastic_model$beta\n    \n    # having at least one parameter\n    while (length(which(estimates[,1]!=0))<1){\n      MSEs = MSEs[-1,]\n      lambda.min = MSEs$lambdas[1]\n      alpha.min = MSEs$alphas[1]\n      elastic_model =  glmnet::glmnet(y =data.matrix(y_train_entry), x = x_train_entry, family = ensr_family,\n                             alpha = alpha.min,lambda=lambda.min,standardize = F)\n      estimates = elastic_model$beta\n    }\n    \n    # calculate metrics\n    \n    # Stopping if there aren't enough observations in the training data\n    if (is.null(stop_test)==F){\n      if (sum(as.numeric(as.character(unlist(y_test_entry))))<stop_test){next}\n    }\n    \n    if (family=='binary'){\n      # AUC\n      predictions = predict(elastic_model, newx=x_test_entry,type = \"response\")\n      model_roc =  pROC::roc(unlist(y_test_entry),as.numeric(predictions),direction=\"<\",quiet=T)\n      model_coords = pROC::coords(model_roc,\"best\", ret=c(\"threshold\", \"specificity\", \"sensitivity\"), transpose=FALSE)\n      model_auc = pROC::auc(model_roc)\n      \n      # Sensitivity and specificity\n      if (prefer_sensitivity==T){\n        coords_to_pick = which(model_coords$sensitivity==max(model_coords$sensitivity))\n      }\n      else {\n        coords_to_pick = which(model_coords$specificity==max(model_coords$specificity))\n      }\n      model_spec <- model_coords[coords_to_pick,2]\n      model_sens <- model_coords[coords_to_pick,3]\n      \n      # store predictions\n      predictions_all[test_indices[[entry]]] = predictions\n      \n      # accuracy, PPV, NPV\n      predictions_bin = ifelse(predictions>model_coords$threshold[coords_to_pick],1,0)\n      confmatrix <- caret::confusionMatrix(as.factor(predictions_bin),as.factor(unlist(y_test_entry)),positive='1')\n      \n      # storing metrics\n      results_df[entry,'fold']=entry\n      results_df[entry,'nrow_train']=nrow(x_train_entry)\n      results_df[entry,'nrow_test']=nrow(x_test_entry)\n      results_df[entry,'ny_train']=sum(as.numeric(as.character(unlist(y_train_entry))))\n      results_df[entry,'ny_test']=sum(as.numeric(as.character(unlist(y_test_entry))))\n      results_df[entry,'AUC']=model_auc\n      results_df[entry,'sensitivity']=model_sens\n      results_df[entry,'specificity']=model_spec\n      results_df[entry,'accuracy']=confmatrix$overall[1]\n      results_df[entry,'PPV']=confmatrix$byClass[3]\n      results_df[entry,'NPV']=confmatrix$byClass[4]\n      \n    }\n    else if (family=='continuous'){\n      \n      # Getting the predictions\n      predictions = predict(elastic_model, newx=x_test_entry,type = \"response\")\n      if (is.null(pred_min)==F){predictions[predictions<pred_min]=pred_min}\n      if (is.null(pred_max)==F){predictions[predictions>pred_max]=pred_max}\n      \n      # store predictions\n      predictions_all[test_indices[[entry]]] = predictions\n      \n      # Getting R2, adjusted R2, RMSE, MSE, MAE\n      R2 = 1-(sum((y_test_entry-predictions)^2)/length(unlist(y_test_entry)))/(sum((y_test_entry-mean(unlist(y_train_entry)))^2)/length(unlist(y_test_entry)))\n      R2_adjusted = 1 - (1-R2)*(length(unlist(y_test_entry))-1)/(length(unlist(y_test_entry))-length(which(estimates!=0))-1)\n      RMSE = caret::RMSE(unlist(y_test_entry),predictions)\n      MSE = RMSE^2\n      MAE = caret::MAE(unlist(y_test_entry),predictions)\n      \n      # storing metrics\n      results_df[entry,'fold']=entry\n      results_df[entry,'nrow_train']=nrow(x_train_entry)\n      results_df[entry,'nrow_test']=nrow(x_test_entry)\n      results_df[entry,'mean_y_train']=mean(unlist(y_train_entry))\n      results_df[entry,'mean_y_test']=mean(unlist(y_test_entry))\n      results_df[entry,'R2']=R2\n      results_df[entry,'R2_adjusted']=R2_adjusted\n      results_df[entry,'RMSE']=RMSE\n      results_df[entry,'MSE']=MSE\n      results_df[entry,'MAE']=MAE\n    }\n    \n    # storing estimates\n    for (predictor in predictors){\n      index = which(rownames(estimates)==predictor)\n      if (length(index)==0){\n        results_df[entry,predictor]<- NA\n      }\n      else{\n        results_df[entry,predictor]<- estimates[index]\n      }\n    }\n    \n    # Storing model\n    models[[entry]]=elastic_model\n    \n  }\n  \n  # remove stored variables\n  rm(x_train_entry,envir = .GlobalEnv)\n  rm(y_train_entry,envir = .GlobalEnv)\n  rm(ensr_lambdas,envir = .GlobalEnv)\n  rm(ensr_cv,envir = .GlobalEnv)\n  rm(ensr_alphas,envir = .GlobalEnv)\n  \n  # Create final results\n  results = list()\n  results$models = models\n  results$metrics = results_df\n  results$predictions = predictions_all\n  \n  # return results\n  return(results)\n}\n\ncoefficient_ranker <- function(data){\n  data_ranked = as.data.frame(t(apply(data,1,function(x){\n    x[x==0]=NA\n    x[x<0&is.na(x)==F]=-order(x[x<0&is.na(x)==F])\n    x[x>0&is.na(x)==F]=order(x[x>0&is.na(x)==F])\n    x\n  })))\n  return(data_ranked)\n}\n\nNLML_plot <- function(results_estimates,percentile=0.90,range=TRUE,title=NULL,subtitle=NULL,xlim=NULL,ylab='Predictor',xlab='Estimate', gradient_values= c(-1.5,-1,-0.5,0,0.25,0.5,0.75,1,1.5,2,2.5)){\n  \n  # Summarize results\n  results_estimates_long <- tidyr::gather(results_estimates, variable, estimate, colnames(results_estimates)[1]:colnames(results_estimates)[ncol(results_estimates)], factor_key=TRUE)\n  summary_estimates <- results_estimates_long |>\n    dplyr::group_by(variable) |>\n    dplyr::summarise(mean_estimate = mean(estimate,na.rm=T),P025 = quantile(estimate, 0.025,na.rm=TRUE),P975 = quantile(estimate, 0.975,na.rm=TRUE))\n  \n  # Set colors\n  green_red_palette <- scales::brewer_pal(type = \"div\", palette = \"RdYlGn\")(11)\n  green_red_palette_dark <- colorspace::darken(green_red_palette, amount = 0.3)\n  green_red_palette_dark_less <- colorspace::darken(green_red_palette, amount = 0.075)\n  \n  # Set limits\n  if (is.null(xlim)==T){\n    xlim = c(min(summary_estimates$P025),max(summary_estimates$P975))\n  }\n  \n  # Make base plot\n  base_plot <- ggplot(summary_estimates[abs(summary_estimates$mean_estimate)>=\n                                          quantile(abs(summary_estimates$mean_estimate),percentile,na.rm=TRUE),],\n                      aes(x=mean_estimate,y=forcats::fct_reorder(variable,mean_estimate)))\n  \n  # Add 95% segments\n  if (range==TRUE){\n    base_plot <- base_plot + geom_segment(aes(x=P025,xend=P975,yend=variable,color=mean_estimate),linewidth=3)\n  }\n  \n  # Finish plot\n  plot <- base_plot +\n    \n    # Add 0 line\n    geom_vline(xintercept = 0, lty = 2, linewidth = 0.2) +\n    \n    # Add means\n    geom_point(aes(fill = mean_estimate),pch = 21,size=3) +\n    \n    # Change colors\n    scale_fill_gradientn(colours = green_red_palette_dark,values = gradient_values)+\n    scale_color_gradientn(colours = green_red_palette_dark_less,values = gradient_values)+\n    \n    # Remove background\n    theme_bw()+\n    \n    # Set names of the x and y axis\n    xlab(xlab)+\n    ylab(ylab)+\n    \n    # Set the x-axis at the top\n    scale_x_continuous(position = \"top\")+\n    \n    # Change themes\n    theme(legend.position=\"none\",\n          axis.text.y = element_text(size = 8,face = \"bold\"),\n          axis.ticks.y = element_blank(),\n          axis.line = element_blank(),\n          plot.title = element_text(hjust = 0.5,face = \"bold\"),\n          plot.subtitle = element_text(hjust = 0.5,face = \"bold\"))+\n    \n    # Correct zoom x\n    coord_cartesian(xlim=xlim)+\n    \n    # Title\n    ggtitle(title,subtitle = subtitle)\n  \n  # Return plot\n  return(plot)\n}\n\nNLML_plot_ranked_split <- function(results_estimates,percentile=0.90,range=TRUE,title=NULL,subtitle=NULL,xlim=NULL,ylab='Predictor',xlab='Estimate', gradient_values= c(-1.5,-1,-0.5,0,0.25,0.5,0.75,1,1.5,2,2.5)){\n  \n  # Summarize results\n  results_estimates_long <- tidyr::gather(results_estimates, variable, estimate, colnames(results_estimates)[1]:colnames(results_estimates)[ncol(results_estimates)], factor_key=TRUE)\n  summary_estimates_positive <- subset(results_estimates_long,estimate>0) |>\n    dplyr::group_by(variable) |>\n    dplyr::summarise(mean_estimate = mean(estimate,na.rm=T),P025 = quantile(estimate, 0.025,na.rm=TRUE),P975 = quantile(estimate, 0.975,na.rm=TRUE))\n  summary_estimates_negative <- subset(results_estimates_long,estimate<0) |>\n    dplyr::group_by(variable) |>\n    dplyr::summarise(mean_estimate = mean(estimate,na.rm=T),P025 = quantile(estimate, 0.025,na.rm=TRUE),P975 = quantile(estimate, 0.975,na.rm=TRUE))\n  summary_estimates <- rbind(summary_estimates_positive,summary_estimates_negative)\n  \n  # Set colors\n  green_red_palette <- scales::brewer_pal(type = \"div\", palette = \"RdYlGn\")(11)\n  green_red_palette_dark <- colorspace::darken(green_red_palette, amount = 0.3)\n  green_red_palette_dark_less <- colorspace::darken(green_red_palette, amount = 0.075)\n  \n  # Set limits\n  if (is.null(xlim)==T){\n    xlim = c(min(summary_estimates$P025),max(summary_estimates$P975))\n  }\n  \n  # Make base plot\n  base_plot <- ggplot(summary_estimates[abs(summary_estimates$mean_estimate)<=\n                                          quantile(abs(summary_estimates$mean_estimate),(1-percentile),na.rm=TRUE),],\n                      aes(x=mean_estimate,y=forcats::fct_reorder(variable,mean_estimate)))\n  \n  # Add 95% segments\n  if (range==TRUE){\n    base_plot <- base_plot + geom_segment(aes(x=P025,xend=P975,yend=variable,color=mean_estimate),linewidth=3)\n  }\n  \n  # Finish plot\n  plot <- base_plot +\n    \n    # Add 0 line\n    geom_vline(xintercept = 0, lty = 2, linewidth = 0.2) +\n    \n    # Add means\n    geom_point(aes(fill = mean_estimate),pch = 21,size=3) +\n    \n    # Change colors\n    scale_fill_gradientn(colours = green_red_palette_dark,values = gradient_values)+\n    scale_color_gradientn(colours = green_red_palette_dark_less,values = gradient_values)+\n    \n    # Remove background\n    theme_bw()+\n    \n    # Set names of the x and y axis\n    xlab(xlab)+\n    ylab(ylab)+\n    \n    # Set the x-axis at the top\n    scale_x_continuous(position = \"top\")+\n    \n    # Change themes\n    theme(legend.position=\"none\",\n          axis.text.y = element_text(size = 8,face = \"bold\"),\n          axis.ticks.y = element_blank(),\n          axis.line = element_blank(),\n          plot.title = element_text(hjust = 0.5,face = \"bold\"),\n          plot.subtitle = element_text(hjust = 0.5,face = \"bold\"))+\n    \n    # Correct zoom x\n    coord_cartesian(xlim=xlim)+\n    \n    # Title\n    ggtitle(title,subtitle = subtitle)\n  \n  # Return plot\n  return(plot)\n}\n\n#### Define UI ####\nui <- fluidPage(\n\n  # Theme of the app\n  theme=bslib::bs_theme(primary = \"#3BA688\", secondary = \"#F39498\",\n                 font_scale = NULL, preset = \"minty\"),\n  # App title\n  titlePanel(h1(HTML(\"Person-specific and Pooled Prediction Models <br/> with Elastic Net Regularized Regression\"),align = \"center\")),\n\n  # Create panels for the sidebar\n  navlistPanel(\n    id = \"tabset\",\n    # Tab 1: Uploading data\n    tabPanel(\"Data\",\n             # Upload data\n             fileInput(\"upload\", \"Upload your data set\",multiple = T,accept='.xlsx')),\n    # Tab 2: Setting preprocessing parameters\n    tabPanel(\"Preprocessing\",\n             \n             # Create bootstrap switch for either a pooled of person-specific model\n             'Pick a model type',\n             shinyWidgets::switchInput(inputId = \"model_type\",label = 'Model type',onLabel = \"Pooled\",offLabel = \"Person-specific\",value = TRUE,width= 'auto'),\n             \n             # Conditional panels for the pooled or person-specific models\n             tabsetPanel(\n               id = \"switcher_pooled_person\",\n               type = \"hidden\",\n               # Pooled model\n               tabPanelBody(\"pooled\",\n                            fluidRow(\n                              column(6,\n                                     # Create checkboxes\n                                     shinyWidgets::pickerInput(inputId = 'predictors_within_con_pooled', label = 'Select within-person continuous predictor(s)', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = TRUE),\n                                     shinyWidgets::pickerInput(inputId = 'predictors_between_con_pooled', label = 'Select between-person continuous predictor(s)', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = TRUE),\n                                     shinyWidgets::pickerInput(inputId = 'predictors_within_cat_pooled', label = 'Select within-person categorical predictor(s)', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = TRUE),\n                                     shinyWidgets::pickerInput(inputId = 'predictors_between_cat_pooled', label = 'Select between-person categorical predictor(s)', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = TRUE),\n                                     shinyWidgets::pickerInput(inputId = 'outcome_pooled', label = 'Select outcome', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = FALSE),\n                                     # Split and cross-validation\n                                     'Pick a split type',\n                                     shinyWidgets::switchInput(inputId = \"split_type_pooled\",label = 'Split type',onLabel = \"Cross-validation\",offLabel = \"Train-test split\",value = TRUE,width= 'auto'),\n                                     tabsetPanel(\n                                       id = \"switcher_split_pooled\",\n                                       type = \"hidden\",\n                                       tabPanelBody(\"cv_pooled\",\n                                                    numericInput(\"nfolds_pooled\", \"Number of folds\", value = 5)),\n                                       tabPanelBody(\"split_pooled\",\n                                                    numericInput(\"split_percentage_pooled\", \"Percentage training data\", value = 80))),\n                                     # Inner folds\n                                     numericInput(\"ensr_cv_pooled\", \"Number of inner folds\", value = 10, min = 1),\n                                     # Number of inner cross-validation repetition\n                                     numericInput(\"repeated_cv_pooled\", \"Number of inner cross-validation repetitions\", value = 1, min = 1)\n                              ),\n                              column(6,\n                                     # Stratified\n                                     shinyWidgets::materialSwitch(inputId = \"stratified_pooled\",label = \"Stratified\", status = \"default\",right = F,value=T),\n                                     # Scaled\n                                     shinyWidgets::materialSwitch(inputId = \"scaled_pooled\",label = \"Scaled     \", status = \"default\",right = F,value=T),\n                                     # Shuffle\n                                     shinyWidgets::materialSwitch(inputId = \"shuffle_pooled\",label = \"Shuffle     \", status = \"default\",right = F,value=T),\n                                     # Number of alphas\n                                     numericInput(\"nalphas_pooled\", \"Number of alphas\", value = 10, min = 2),\n                                     # Number of lambdas\n                                     numericInput(\"nlambdas_pooled\", \"Number of lambdas\", value = 10, min = 1),\n                                     # Seed\n                                     numericInput(\"seed_pooled\", \"Seed\", value = 404, min = 1),\n                                     # Analysis family\n                                     'Pick a family type for the analyses',\n                                     shinyWidgets::switchInput(inputId = \"family_pooled\",label = 'Family',onLabel = \"Binary\",offLabel = \"Continuous\",value = TRUE,width= 'auto'),\n                                     tabsetPanel(\n                                       id = \"switcher_family_pooled\",\n                                       type = \"hidden\",\n                                       tabPanelBody(\"binary_family_pooled\",\n                                                    'Pick the focus of the models',\n                                                    switchInput(inputId = \"prefer_sensitivity_pooled\",label = 'Preference',onLabel = \"Sensitivity\",offLabel = \"Specificity\",value = TRUE,width= 'auto'),\n                                                    numericInput(\"stop_train_pooled\", \"Minimum number of positive observations in the training data\", value = 5),\n                                                    numericInput(\"stop_test_pooled\", \"Minimum number of positive observations in the testing data\", value = 1)),\n                                       tabPanelBody(\"continuous_family_pooled\",\n                                                    numericInput(\"pred_min_pooled\", \"Minimum value of the predictions\", value = NULL),\n                                                    numericInput(\"pred_max_pooled\", \"Maximum value of the predictions\", value = NULL)))\n                              )\n                            )),\n               # Person-specific model\n               tabPanelBody(\"person_specific\",\n                            fluidRow(\n                              column(6,\n                                     # Create checkboxes\n                                     shinyWidgets::pickerInput(inputId = 'predictors_con_person', label = 'Select continuous predictor(s)', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = TRUE),\n                                     shinyWidgets::pickerInput(inputId = 'predictors_cat_person', label = 'Select categorical predictor(s)', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = TRUE),\n                                     shinyWidgets::pickerInput(inputId = 'outcome_person', label = 'Select outcome', choices = NULL,\n                                                 options = list(`actions-box` = TRUE, 'live-search' = TRUE), multiple = FALSE),\n                                     \n                                     # Split and cross-validation\n                                     'Pick a split type',\n                                     shinyWidgets::switchInput(inputId = \"split_type_person\",label = 'Split type',onLabel = \"Cross-validation\",offLabel = \"Train-test split\",value = TRUE,width= 'auto'),\n                                     tabsetPanel(\n                                       id = \"switcher_split_person\",\n                                       type = \"hidden\",\n                                       tabPanelBody(\"cv_person\",\n                                                    numericInput(\"nfolds_person\", \"Number of outer folds\", value = 5)),\n                                       tabPanelBody(\"split_person\",\n                                                    numericInput(\"split_percentage_person\", \"Percentage training data\", value = 80))),\n                                     # Inner folds\n                                     numericInput(\"ensr_cv_person\", \"Number of inner folds\", value = 10, min = 1),\n                                     # Number of inner cross-validation repetition\n                                     numericInput(\"repeated_cv_person\", \"Number of inner cross-validation repetitions\", value = 1, min = 1)\n                              ),\n                              column(6,\n                                     # Stratified\n                                     shinyWidgets::materialSwitch(inputId = \"stratified_person\",label = \"Stratified\", status = \"default\",right = F,value=T),\n                                     # Scaled\n                                     shinyWidgets::materialSwitch(inputId = \"scaled_person\",label = \"Scaled     \", status = \"default\",right = F,value=T),\n                                     # Shuffle\n                                     shinyWidgets::materialSwitch(inputId = \"shuffle_person\",label = \"Shuffle     \", status = \"default\",right = F,value=T),\n                                     # Number of alphas\n                                     numericInput(\"nalphas_person\", \"Number of alphas\", value = 10, min = 2),\n                                     # Number of lambdas\n                                     numericInput(\"nlambdas_person\", \"Number of lambdas\", value = 10, min = 1),\n                                     # Seed\n                                     numericInput(\"seed_person\", \"Seed\", value = 404, min = 1),\n                                     # Analysis family\n                                     'Pick a family type for the analyses',\n                                     shinyWidgets::switchInput(inputId = \"family_person\",label = 'Family',onLabel = \"Binary\",offLabel = \"Continuous\",value = TRUE,width= 'auto'),\n                                     tabsetPanel(\n                                       id = \"switcher_family_person\",\n                                       type = \"hidden\",\n                                       tabPanelBody(\"binary_family_person\",\n                                                    'Pick the focus of the models',\n                                                    switchInput(inputId = \"prefer_sensitivity_person\",label = 'Preference',onLabel = \"Sensitivity\",offLabel = \"Specificity\",value = TRUE,width= 'auto'),\n                                                    numericInput(\"stop_train_person\", \"Minimum number of positive observations in the training data\", value = 5),\n                                                    numericInput(\"stop_test_person\", \"Minimum number of positive observations in the testing data\", value = 1)),\n                                       tabPanelBody(\"continuous_family_person\",\n                                                    numericInput(\"pred_min_person\", \"Minimum value of the predictions\", value = NULL),\n                                                    numericInput(\"pred_max_person\", \"Maximum value of the predictions\", value = NULL)))\n                              )\n                            )))),\n    \n    # Tab 3: Analysis\n    tabPanel(\"Model Training and Testing\",\n             HTML('Press button to start the analyses <br/>'),\n             actionButton(\"start_analysis\", \"Start!\"),\n             shinyWidgets::progressBar(id = \"pb\", value = 0, display_pct = T)),\n    # Tab 4: Displaying the results\n    tabPanel(\"Results\",\n             tabsetPanel(\n               id = \"switcher_family_results\",\n               type = \"hidden\",\n               tabPanelBody(\"results_family_pooled\",\n                            HTML('Download results <br/>'),\n                            downloadButton(\"download_pooled\"),\n                            DT::DTOutput(\"results_table_pooled_average\"),style = \"height:800px; overflow-y: scroll;overflow-x: scroll;\",\n                            DT::DTOutput(\"results_table_pooled_metrics\"),style = \"height:800px; overflow-y: scroll;overflow-x: scroll;\",\n                            DT::DTOutput(\"results_table_pooled_estimates\"),style = \"height:800px; overflow-y: scroll;overflow-x: scroll;\"\n               ),\n               tabPanelBody(\"results_family_person\",\n                            HTML('Download results <br/>'),\n                            downloadButton(\"download_person\"),\n                            DT::DTOutput(\"results_table_person_average\"),style = \"height:800px; overflow-y: scroll;overflow-x: scroll;\",\n                            DT::DTOutput(\"results_table_person\"),style = \"height:800px; overflow-y: scroll;overflow-x: scroll;\"\n               ))\n    ),\n    # Tab 5: Displaying the results\n    tabPanel(\"Plots\",\n             HTML('Download plot <br/>'),\n             downloadButton(\"download_plot\"),\n             HTML('<br/>'),\n             'Pick a plot type',\n             shinyWidgets::switchInput(inputId = \"plot_type\",label = 'Plot type',onLabel = \"Parametric\",offLabel = \"Nonparametric\",value = TRUE,width= 'auto'),\n             fluidRow(\n               column(6,\n                      numericInput(\"percentile\", \"Percentile\", value = 0.9,min = 0,max = 1),\n                      shinyWidgets::materialSwitch(inputId = \"range\",label = \"Display Range\", status = \"default\",right = F,value=T),\n                      sliderInput(\"xlim\", \"Plot range\", value = c(-2,2), min = -10, max = 10,step=0.5),\n                      sliderInput('gradient', \"Color range\", value = c(-1.5,2.5), min = -5, max = 5,step=0.5)\n               ),\n               column(6,\n                      textInput(\"title\", \"Title\",value=NULL),\n                      textInput(\"subtitle\", \"Subtitle\",value=NULL),\n                      textInput(\"ylab\", \"Label y-axis\",value='Predictor'),\n                      textInput(\"xlab\", \"Label x-axis\",value='Estimate')\n               )\n             ),\n             plotOutput(\"plot_estimates\"))\n  )\n)\n\n#### Define server logic ####\nserver <- function(input, output, session) {\n\n  # Create reactive element for data\n  data_to_analyse <- reactive({\n    # Waiting for input\n    req(input$upload)\n    # Making list of data sets\n    data_lists <- list()\n    for (entry in input$upload$datapath){\n      data_lists[[length(data_lists)+1]]<-openxlsx::read.xlsx(entry)\n    }\n    # Returning list of data sets\n    data_lists\n  })\n  \n  # Create reactive elements for split/CV\n  split <- reactiveValues(value_pooled = NA,value_person=NA)\n  ext_cv_folds <- reactiveValues(value_pooled = NA,value_person=NA)\n  \n  # Create reactive elements for results\n  results_person <- reactiveValues(results = data.frame(NA),results_ranked=data.frame(NA),\n                                   results_metrics_average = data.frame(NA),results_metrics_median = data.frame(NA))\n  results_pooled <- reactiveValues(results_estimates = data.frame(NA),results_estimates_ranked = data.frame(NA), results_metrics = data.frame(NA),\n                                   results_metrics_average = data.frame(NA),results_metrics_median = data.frame(NA))\n  \n  # Switch preprocessing panels for model type\n  observeEvent(input$model_type, {\n    updateTabsetPanel(inputId = \"switcher_pooled_person\", selected = ifelse(input$model_type,'pooled','person_specific'))\n  })\n  \n  # Switch preprocessing panels for split/CV\n  observeEvent(input$split_type_pooled, {\n    updateTabsetPanel(inputId = \"switcher_split_pooled\", selected = ifelse(input$split_type_pooled,'cv_pooled','split_pooled'))})\n  observeEvent(input$split_type_person, {\n    updateTabsetPanel(inputId = \"switcher_split_person\", selected = ifelse(input$split_type_person,'cv_person','split_person'))})\n  \n  # Switch preprocessing panels for family\n  observeEvent(input$family_pooled, {\n    updateTabsetPanel(inputId = \"switcher_family_pooled\", selected = ifelse(input$family_pooled,'binary_family_pooled','continuous_family_pooled'))\n  })\n  observeEvent(input$family_person, {\n    updateTabsetPanel(inputId = \"switcher_family_person\", selected = ifelse(input$family_person,'binary_family_person','continuous_family_person'))\n  })\n  \n  # Update selection list for predictors and outcome\n  observe({\n    # Create common predictors\n    predictors <- colnames(data_to_analyse()[[1]])\n    if (length(data_to_analyse())>1){\n      for (i in 1:length(data_to_analyse())){\n        predictors<- intersect(predictors, colnames(data_to_analyse()[[i]]))\n      }\n    }\n\n    # Update predictor selectors\n    shinyWidgets::updatePickerInput(session, 'predictors_con_person', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'predictors_cat_person', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'predictors_within_con_pooled', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'predictors_within_cat_pooled', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'predictors_between_con_pooled', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'predictors_between_cat_pooled', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'outcome_person', choices = predictors)\n    shinyWidgets::updatePickerInput(session, 'outcome_pooled', choices = predictors)\n  })\n  \n  # Run analyses\n  observeEvent(input$start_analysis, {\n    # Perform pooled analyses\n    if (input$model_type==T){\n      # Create one data set\n      data_pooled <- list()\n      for (entry in 1:length(data_to_analyse())){\n        data_pooled[[entry]] <- dplyr::select(data_to_analyse()[[entry]],c(input$predictors_within_con_pooled,input$predictors_between_con_pooled,\n                                                                input$predictors_within_cat_pooled,input$predictors_between_cat_pooled,\n                                                                input$outcome_pooled))\n        data_pooled[[entry]]$entry <- entry\n      }\n      data_pooled <- dplyr::bind_rows(data_pooled)\n      # Get values for split and folds      \n      if(input$split_type_pooled==T){\n      split$value_pooled <- NULL\n      ext_cv_folds$value_pooled <- input$nfolds_pooled}\n      else if(input$split_type_pooled==F){\n        split$value_pooled <- input$split_percentage_pooled\n        ext_cv_folds$value_pooled <-NULL}\n    \n      # run model\n      shinyWidgets::updateProgressBar(session = session, id = \"pb\", value = 0)\n      results_model <- elastic_net_wrapper_pooled(data=data_pooled,by='entry',predictors_con=input$predictors_within_con_pooled,predictors_cat=input$predictors_within_cat_pooled,\n                                                  between_predictors_con = input$predictors_between_con_pooled,between_predictors_cat = input$predictors_between_cat_pooled,\n                                                  outcome=input$outcome_pooled,split=split$value_pooled, outer_cv=ext_cv_folds$value_pooled, stratified=input$stratified_pooled,scaling=input$scaled_pooled,\n                                                  repeated_cv=input$repeated_cv_pooled,ensr_cv=input$ensr_cv_pooled,ensr_alphas=seq(0, 1, length = input$nalphas_pooled),ensr_lambdas=input$nlambdas_pooled,seed=input$seed_pooled,\n                                                  shuffle=input$shuffle_pooled,stop_test=input$stop_test_pooled,family=ifelse(input$family_pooled,'binary','continuous'),\n                                                  pred_min=input$pred_min_pooled,pred_max=input$pred_max_pooled,prefer_sensitivity=input$prefer_sensitivity_pooled)\n      shinyWidgets::updateProgressBar(session = session, id = \"pb\", value = 100)\n      # Return results\n      results_pooled$results_estimates <- results_model$results_pooled_model\n      results_pooled$results_metrics <- results_model$results_by\n      results_pooled$results_metrics_average <- aggregate(dplyr::select(results_model$results_by,-c('by','fold')),list(by=results_model$results_by$by),mean,na.rm=T)\n      results_pooled$results_metrics_average$type <- 'mean'\n      results_pooled$results_metrics_average <- aggregate(dplyr::select(results_pooled$results_metrics_average,-c('by','type')),list(type=results_pooled$results_metrics_average$type),mean,na.rm=T)\n      results_pooled$results_metrics_median <- aggregate(dplyr::select(results_model$results_by,-c('by','fold')),list(by=results_model$results_by$by),median,na.rm=T)\n      results_pooled$results_metrics_median$type <- 'median'\n      results_pooled$results_metrics_median <- aggregate(dplyr::select(results_pooled$results_metrics_median,-c('by','type')),list(type=results_pooled$results_metrics_median$type),median,na.rm=T)\n      \n      # Rename columns\n      results_pooled$results_metrics <- results_pooled$results_metrics |>\n        dplyr::rename(\n          participant = by\n        )\n      \n      # Create ranked results\n      results_pooled$results_estimates_ranked <- results_pooled$results_estimates\n      results_pooled$results_estimates_ranked[,c(input$predictors_within_con_pooled,input$predictors_between_con_pooled,input$predictors_within_cat_pooled,input$predictors_between_cat_pooled)] <- coefficient_ranker(results_pooled$results_estimates_ranked[,c(input$predictors_within_con_pooled,input$predictors_between_con_pooled,input$predictors_within_cat_pooled,input$predictors_between_cat_pooled)])\n    }\n    # Perform person-specific analyses\n    else if (input$model_type==F){\n      # Create final results dataframe\n      results_all <- data.frame()\n      shinyWidgets::updateProgressBar(session = session, id = \"pb\", value = 0)\n      \n      # Get values for split and folds\n        if(input$split_type_person==T){\n          split$value_person <- NULL\n          ext_cv_folds$value_person <- input$nfolds_person}\n        else if(input$split_type_person==F){\n          split$value_person <- input$split_percentage_person\n          ext_cv_folds$value_person <-NULL}\n\n      # Loop over data sets\n      for (entry in 1:length(data_to_analyse())){\n        results_model <- elastic_net_wrapper(data=data_to_analyse()[[entry]],predictors_con=input$predictors_con_person,predictors_cat=input$predictors_cat_person,\n                                             outcome=input$outcome_person,split=split$value_person, outer_cv=ext_cv_folds$value_person, stratified=input$stratified_person,scaling=input$scaled_person,\n                                             repeated_cv=input$repeated_cv_person,ensr_cv=input$ensr_cv_person,ensr_alphas=seq(0, 1, length = input$nalphas_person),ensr_lambdas=input$nlambdas_person,seed=input$seed_person,\n                                             shuffle=input$shuffle_person,stop_train=input$stop_train_person,stop_test=input$stop_test_person,family=ifelse(input$family_person,'binary','continuous'),\n                                             pred_min=input$pred_min_person,pred_max=input$pred_max_person,prefer_sensitivity=input$prefer_sensitivity_person)\n        shinyWidgets::updateProgressBar(session = session, id = \"pb\", value = (entry/length(data_to_analyse()))*100)\n        # Store the results\n        if (nrow(results_model$metrics)!=0){\n          results_model$metrics$entry <- entry\n          results_all[((nrow(results_all)+1):(nrow(results_all)+nrow(results_model$metrics))),1:ncol(results_model$metrics)] <- results_model$metrics}\n      }\n      # Return results\n      results_person$results <- results_all\n      results_person$results_metrics_average <- aggregate(dplyr::select(results_all,-c('entry','fold')),list(entry=results_all$entry),mean,na.rm=T)\n      results_person$results_metrics_average$type <- 'mean'\n      results_person$results_metrics_average <- aggregate(dplyr::select(results_person$results_metrics_average,-c('entry','type')),list(type=results_person$results_metrics_average$type),mean,na.rm=T)\n      results_person$results_metrics_median <- aggregate(dplyr::select(results_all,-c('entry','fold')),list(entry=results_all$entry),median,na.rm=T)\n      results_person$results_metrics_median$type <- 'median'\n      results_person$results_metrics_median <- aggregate(dplyr::select(results_person$results_metrics_median,-c('entry','type')),list(type=results_person$results_metrics_median$type),median,na.rm=T)\n      \n      # Reorder columns\n      results_person$results <- results_person$results[,c(ncol(results_person$results),1:(ncol(results_person$results)-1))]\n      \n      # Rename columns\n      results_person$results <- results_person$results |>\n        dplyr::rename(\n          participant = entry\n        )\n      \n      # Create ranked results\n      results_person$results_ranked <- results_person$results\n      results_person$results_ranked[,c(input$predictors_con_person,input$predictors_cat_person)] <- coefficient_ranker(results_person$results_ranked[,c(input$predictors_con_person,input$predictors_cat_person)])\n    }\n  })\n  \n  # Show table\n  observeEvent(input$model_type, {\n    # Switch panels\n    updateTabsetPanel(inputId = \"switcher_family_results\", selected = ifelse(input$model_type,'results_family_pooled','results_family_person'))\n    # Results for pooled model\n    if (input$model_type==T){\n      # Show table\n      output$results_table_pooled_average <- DT::renderDT({\n        DT::datatable(rbind(results_pooled$results_metrics_average,results_pooled$results_metrics_median),\n                  options = list(paging = FALSE),caption = htmltools::tags$caption( style = 'caption-side: top; color:black;  font-size:150% ;','Table 1: Average and median of the metrics'))\n      })\n      output$results_table_pooled_metrics <- DT::renderDT({\n        DT::datatable(results_pooled$results_metrics, options = list(paging = FALSE),\n                  caption = htmltools::tags$caption(style = 'caption-side: top; color:black;  font-size:150% ;','Table 2: Full metrics'))\n      })\n      output$results_table_pooled_estimates <- DT::renderDT({\n        DT::datatable(results_pooled$results_estimates, options = list(paging = FALSE),\n                  caption = htmltools::tags$caption(style = 'caption-side: top; color:black;  font-size:150% ;','Table 3: Estimates'))\n      })\n    }\n    # Results for person-specific model\n    else if (input$model_type==F){\n      output$results_table_person_average <- DT::renderDT({\n        DT::datatable(rbind(results_person$results_metrics_average,results_person$results_metrics_median), options = list(paging = FALSE),\n                  caption = htmltools::tags$caption(style = 'caption-side: top; color:black;  font-size:150% ;','Table 1: Average and median of the metrics and estimates'))\n      })\n      output$results_table_person <- DT::renderDT({\n        DT::datatable(results_person$results, options = list(paging = FALSE),\n                  caption = htmltools::tags$caption(style = 'caption-side: top; color:black;  font-size:150% ;','Table 2: Full metrics and estimates'))\n      })\n    }\n  })\n  \n  # Download data pooled\n  output$download_pooled <- downloadHandler(\n    filename = function() {'results_pooled.xlsx'},\n    content = function(file) {\n      # Create workbook\n      OUT <- openxlsx::createWorkbook()\n      \n      # Add some sheets to the workbook\n      openxlsx::addWorksheet(OUT, \"average_metrics\")\n      openxlsx::addWorksheet(OUT, \"full_metrics\")\n      openxlsx::addWorksheet(OUT, \"full_estimates\")\n      \n      # Write the data to the sheets\n      openxlsx::writeData(OUT, sheet = \"average_metrics\", x = rbind(results_pooled$results_metrics_average,results_pooled$results_metrics_median))\n      openxlsx::writeData(OUT, sheet = \"full_metrics\", x = results_pooled$results_metrics)\n      openxlsx::writeData(OUT, sheet = \"full_estimates\", x = results_pooled$results_estimates)\n      \n      # Export the file\n      openxlsx::saveWorkbook(OUT, file)\n    }\n  )\n  \n  # Download data person\n  output$download_person <- downloadHandler(\n    filename = function() {'results_person.xlsx'},\n    content = function(file) {\n      # Create workbook\n      OUT <- openxlsx::createWorkbook()\n      \n      # Add some sheets to the workbook\n      openxlsx::addWorksheet(OUT, \"average_metrics_and_estimated\")\n      openxlsx::addWorksheet(OUT, \"full_metrics_and_estmates\")\n      \n      # Write the data to the sheets\n      openxlsx::writeData(OUT, sheet = \"average_metrics_and_estimated\", x = rbind(results_person$results_metrics_average,results_person$results_metrics_median))\n      openxlsx::writeData(OUT, sheet = \"full_metrics_and_estmates\", x = results_person$results)\n      \n      # Export the file\n      openxlsx::saveWorkbook(OUT, file)\n    }\n  )\n  \n  # Create reactive elements for plots\n  plot_estimates_pooled_parametric <- reactive({\n    NLML_plot(data.frame(t(apply(dplyr::select(results_pooled$results_estimates,c(input$predictors_within_con_pooled,input$predictors_between_con_pooled,\n                                                                                  input$predictors_within_cat_pooled,input$predictors_between_cat_pooled)),2,mean,na.rm=T))),\n              percentile = input$percentile,range = input$range,title = input$title,subtitle = input$subtitle,\n              xlim = input$xlim,ylab = input$ylab,xlab = input$xlab,gradient_values = seq(from=input$gradient[1],to=input$gradient[2],length.out=11))})\n  \n  plot_estimates_pooled_nonparametric <- reactive({\n    NLML_plot(dplyr::select(aggregate(dplyr::select(results_person$results,-c('participant','fold')),list(participant=results_person$results$participant),mean,na.rm=T),c(input$predictors_con_person,input$predictors_cat_person)),\n              percentile = input$percentile,range = input$range,title = input$title,subtitle = input$subtitle,\n              xlim = input$xlim,ylab = input$ylab,xlab = input$xlab,gradient_values = seq(from=input$gradient[1],to=input$gradient[2],length.out=11))})\n  \n  plot_estimates_person_parametric <- reactive({\n    NLML_plot_ranked_split(data.frame(t(apply(dplyr::select(results_pooled$results_estimates_ranked,c(input$predictors_within_con_pooled,input$predictors_between_con_pooled,\n                                                                                                      input$predictors_within_cat_pooled,input$predictors_between_cat_pooled)),2,mean,na.rm=T))),\n                           percentile = input$percentile,range = input$range,title = input$title,subtitle = input$subtitle,\n                           xlim = input$xlim,ylab = input$ylab,xlab = input$xlab,gradient_values = seq(from=input$gradient[1],to=input$gradient[2],length.out=11))})\n  \n  plot_estimates_person_nonparametric <- reactive({\n    NLML_plot_ranked_split(dplyr::select(aggregate(dplyr::select(results_person$results_ranked,-c('participant','fold')),list(participant=results_person$results_ranked$participant),mean,na.rm=T),c(input$predictors_con_person,input$predictors_cat_person)),\n                           percentile = input$percentile,range = input$range,title = input$title,subtitle = input$subtitle,\n                           xlim = input$xlim,ylab = input$ylab,xlab = input$xlab,gradient_values = seq(from=input$gradient[1],to=input$gradient[2],length.out=11))\n  })\n  # Plot estimates\n  observeEvent(req(input$tabset == 'Plots'),{\n    observeEvent(input$plot_type,{\n      if (input$plot_type==T){\n        if (input$model_type==T){\n          output$plot_estimates <- renderPlot({plot_estimates_pooled_parametric()},res = 144)\n        }\n        else if (input$model_type==F){\n          output$plot_estimates <- renderPlot({plot_estimates_pooled_nonparametric()},res = 144)\n        }\n      }\n      else if (input$plot_type==F){\n        if (input$model_type==T){\n          output$plot_estimates <- renderPlot({plot_estimates_person_parametric()},res = 144)\n        }\n        else if (input$model_type==F){\n          output$plot_estimates <- renderPlot({plot_estimates_person_nonparametric()},res = 144)\n        }\n      }\n    })\n  })\n  \n  # Download plot\n  observeEvent(req(input$tabset == 'Plots'),{\n    output$download_plot <- downloadHandler(\n      filename = function() {'plot.png'},\n      content = function(file) {\n        png(file,units='in',width=4, height=2.5, res = 144)\n        if (input$plot_type==T){\n          if (input$model_type==T){\n            plot(plot_estimates_pooled_parametric())\n          }\n          else if (input$model_type==F){\n            plot(plot_estimates_pooled_nonparametric())\n          }\n        }\n        else if (input$plot_type==F){\n          if (input$model_type==T){\n            plot(plot_estimates_person_parametric())\n          }\n          else if (input$model_type==F){\n            plot(plot_estimates_person_nonparametric())\n          }\n        }\n        dev.off()\n      })\n  })\n\n}\n\n#### Run the application ####\nshinyApp(ui = ui, server = server)\n","type":"text"}]
